// Matrix multiplication kernel called by MatMul()
 #define n 128
 #define BLOCK_SIZE 16
#include<stdio.h>

 struct Matrix
               {
                   int width;
                   int height;
                   int *element;
               } ;

__global__ void MatMulKernel(Matrix A, Matrix B, Matrix C)
{
    // Each thread computes one element of C
    // by accumulating results into Cvalue
    float Cvalue = 0;
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    for (int e = 0; e < A.width; ++e)
        {Cvalue += A.element[row * A.width + e]
                * B.element[e * B.width + col];
    C.element[row * C.width + col] = Cvalue;}
}

 int main()
 {
                // Matrices are stored in row-major order:
               // M(row, col) = *(M.elements + row * M.width + col)
               
               // Thread block size
               // Forward declaration of the matrix multiplication kernel

               __global__ void MatMulKernel(const Matrix, const Matrix, Matrix);

               // Matrix multiplication - Host code
               // Matrix dimensions are assumed to be multiples of BLOCK_SIZE
               
               Matrix A, B, C, d_A, d_B, d_C;

               int row = blockIdx.y * blockDim.y + threadIdx.y;
               int col = blockIdx.x * blockDim.x + threadIdx.x;

               
               A.width=N;
               A.height=N;B.width=N;B.height=N;
               
               

               for(int i=0; i<200; i++)
               {
                 A.element[row*B.width+i]=i+3;
                 A.element+=1;
                 B.element[row*B.width+i]=i+2;
                 B.element+=1;
               }
               
              
                   // Load A and B to device memory
                     float t1= clock();
                     //Matrix d_A;
                     d_A.width = A.width; 
                     d_A.height = A.height;
                     size_t size = A.width * A.height * sizeof(int);
                     cudaMalloc((void**)&d_A.element, size);
                     cudaMemcpy(d_A.element, A.element, size,cudaMemcpyHostToDevice);

                     //Matrix d_B;
                     d_B.width = B.width; d_B.height = B.height;
                     size_t size1 = B.width * B.height * sizeof(int);
                     cudaMalloc((void**)&d_B.element, size1);
                     cudaMemcpy(d_B.element, B.element, size1,cudaMemcpyHostToDevice);

                     // Allocate C in device memory

                     //Matrix d_C;
                     d_C.width = B.width; d_C.height = A.height;
                     size = B.width * A.height * sizeof(int);
                     cudaMalloc((void**)&d_C.element, size);

                     // Invoke kernel
                     dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);
                     dim3 dimGrid(B.width / dimBlock.x, A.height / dimBlock.y);
                     MatMulKernel<<<dimGrid, dimBlock>>>(d_A, d_B, d_C);
                      
                     // Read C from device memory
                     cudaMemcpy(C.element, d_C.element, size, cudaMemcpyDeviceToHost);
                     float t2= clock();
                     float t3= (t2-t1);
                     printf("\n time in gpu%f",t3);
                     // Free device memory
                     cudaFree(d_A.element);
                     cudaFree(d_B.element);
                     cudaFree(d_C.element);
                 
  
 }
